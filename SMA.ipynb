{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NEP\n"
      ],
      "metadata": {
        "id": "W2lSs0b8Ytp4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKWe7R32Yl57"
      },
      "outputs": [],
      "source": [
        "#datset-https://www.kaggle.com/datasets/rishabh6377/india-national-education-policy2020-tweets-dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Load dataset\n",
        "education = pd.read_csv(\"../input/india-national-education-policy2020-tweets-dataset/NEP_2020_english_tweet.csv\")\n",
        "\n",
        "# Download stopwords if needed\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Preparing stopwords, keeping n't words like \"hasn't\"\n",
        "stopword_list = [word for word in stopwords.words('english') if \"n't\" not in word]\n",
        "\n",
        "# Text Preprocessing\n",
        "def preprocess(text):\n",
        "    text = text.strip().lower()\n",
        "    text = re.sub(r'(@\\w+|#\\w+|https?://\\S+|www\\.\\S+)', '', text)  # Remove mentions, hashtags, links\n",
        "    text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))  # Remove punctuation\n",
        "    words = [word for word in text.split() if word not in stopword_list and len(word) > 1 and not word.isdigit()]\n",
        "    return \" \".join(words)\n",
        "\n",
        "education['Processed'] = education['Tweet'].apply(preprocess)\n",
        "\n",
        "# Sentiment Functions\n",
        "def get_subjectivity(text):\n",
        "    return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "def get_polarity(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "def get_sentiment(polarity):\n",
        "    if polarity < 0:\n",
        "        return 'Negative'\n",
        "    elif polarity == 0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Positive'\n",
        "\n",
        "# Apply Sentiment Analysis\n",
        "education['subjectivity'] = education['Processed'].apply(get_subjectivity)\n",
        "education['polarity'] = education['Processed'].apply(get_polarity)\n",
        "education['Sentiment'] = education['polarity'].apply(get_sentiment)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8,6))\n",
        "education['Sentiment'].value_counts().plot(kind='bar', color='skyblue')\n",
        "plt.xlabel(\"Sentiments\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Sentiment Analysis of NEP 2020 Tweets\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IPL"
      ],
      "metadata": {
        "id": "vUyJfdiCY21K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset-https://www.kaggle.com/datasets/patrickb1912/ipl-complete-dataset-20082020\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data\n",
        "deliveries = pd.read_csv('/content/ipl/deliveries.csv')\n",
        "\n",
        "# Basic preprocessing: remove missing batter or bowler\n",
        "deliveries = deliveries.dropna(subset=['batter', 'bowler'])\n",
        "\n",
        "# --- Plot 1: Total Runs by Each Batting Team ---\n",
        "team_runs = deliveries.groupby('batting_team')['batsman_runs'].sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "team_runs.plot(kind='bar', color='skyblue')\n",
        "plt.title('Total Runs by Each Batting Team')\n",
        "plt.xlabel('Batting Team')\n",
        "plt.ylabel('Total Batsman Runs')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# --- Plot 2: Top Wicket-Taking Bowling Teams ---\n",
        "# Assume if a wicket falls (not run out), the bowler gets the credit\n",
        "wickets = deliveries[deliveries['batsman_runs'] == 0]\n",
        "team_wickets = wickets['bowling_team'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "team_wickets.plot(kind='bar', color='salmon')\n",
        "plt.title('Wickets Taken by Each Bowling Team')\n",
        "plt.xlabel('Bowling Team')\n",
        "plt.ylabel('Wickets')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# --- Plot 3: Top 10 Batters by Total Runs ---\n",
        "top_batters = deliveries.groupby('batter')['batsman_runs'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "top_batters.plot(kind='barh', color='lightgreen')\n",
        "plt.title('Top 10 Batters by Runs')\n",
        "plt.xlabel('Total Runs')\n",
        "plt.ylabel('Batter')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# --- Plot 4: Top 10 Bowlers by Wickets ---\n",
        "top_bowlers = deliveries[deliveries['batsman_runs'] == 0]['bowler'].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "top_bowlers.plot(kind='barh', color='violet')\n",
        "plt.title('Top 10 Bowlers by Wickets')\n",
        "plt.xlabel('Wickets')\n",
        "plt.ylabel('Bowler')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# --- Plot 5: Runs per Over (Overall) ---\n",
        "runs_per_over = deliveries.groupby('over')['batsman_runs'].sum()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.lineplot(x=runs_per_over.index, y=runs_per_over.values, marker='o', color='orange')\n",
        "plt.title('Total Runs Scored per Over')\n",
        "plt.xlabel('Over Number')\n",
        "plt.ylabel('Runs')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_QMDLMK5Y3Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amazon Product"
      ],
      "metadata": {
        "id": "vdScxAc9ZpGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset-https://www.kaggle.com/datasets/promptcloud/amazon-product-reviews-dataset/data\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the data\n",
        "reviews = pd.read_csv('/mnt/data/amazon_com-product_reviews__20200101_20200331_sample.csv')\n",
        "\n",
        "# Keep only necessary columns\n",
        "reviews = reviews[['Review Content', 'Review Rating']]\n",
        "\n",
        "# Drop missing reviews\n",
        "reviews = reviews.dropna(subset=['Review Content'])\n",
        "\n",
        "# --- Sentiment Analysis ---\n",
        "def get_polarity(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "def get_sentiment(score):\n",
        "    if score < 0:\n",
        "        return 'Negative'\n",
        "    elif score == 0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Positive'\n",
        "\n",
        "# Apply functions\n",
        "reviews['Polarity'] = reviews['Review Content'].apply(get_polarity)\n",
        "reviews['Sentiment'] = reviews['Polarity'].apply(get_sentiment)\n",
        "\n",
        "# --- Plot 1: Sentiment Distribution ---\n",
        "plt.figure(figsize=(8,5))\n",
        "reviews['Sentiment'].value_counts().plot(kind='bar', color='lightgreen')\n",
        "plt.title('Sentiment Analysis of Reviews')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.show()\n",
        "\n",
        "# --- Plot 2: Rating Distribution (Pie Chart) ---\n",
        "plt.figure(figsize=(6,6))\n",
        "reviews['Review Rating'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired.colors)\n",
        "plt.title('Review Rating Distribution')\n",
        "plt.ylabel('')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P4eKzedRbI_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Brand Twitter analysis-US Airlines"
      ],
      "metadata": {
        "id": "E1FQoLyAc812"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset-https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment/data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "df = pd.read_csv(\"/kaggle/input/twitter-airline-sentiment/Tweets.csv\")\n",
        "df.head()\n",
        "sns.countplot(x=\"airline_sentiment\", data=df, palette=\"viridis\")\n",
        "plt.title(\"Sentiment Distribution\")\n",
        "plt.show()\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    tweet = re.sub(r\"http\\S+|@\\S+|[^a-zA-Z\\s]\", \"\", tweet)\n",
        "    tweet = tweet.lower()\n",
        "    tweet = \" \".join(word for word in tweet.split() if word not in stop_words)\n",
        "    return tweet\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_tweet)\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "for sentiment in ['positive', 'negative', 'neutral']:\n",
        "    text = \" \".join(df[df['airline_sentiment'] == sentiment]['clean_text'])\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"WordCloud - {sentiment.capitalize()} Tweets\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PD86bKSIc_Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative Tweet reviews-Amazon Product"
      ],
      "metadata": {
        "id": "Al0o5Ce-ex6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset-https://www.kaggle.com/datasets/promptcloud/amazon-product-reviews-dataset/data\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the data\n",
        "reviews = pd.read_csv('/mnt/data/amazon_com-product_reviews__20200101_20200331_sample.csv')\n",
        "\n",
        "# Keep only necessary columns\n",
        "reviews = reviews[['Review Content', 'Review Rating']]\n",
        "\n",
        "# Drop missing reviews\n",
        "reviews = reviews.dropna(subset=['Review Content'])\n",
        "\n",
        "# --- Sentiment Analysis ---\n",
        "def get_polarity(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "def get_sentiment(score):\n",
        "    if score < 0:\n",
        "        return 'Negative'\n",
        "    elif score == 0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Positive'\n",
        "\n",
        "# Apply functions\n",
        "reviews['Polarity'] = reviews['Review Content'].apply(get_polarity)\n",
        "reviews['Sentiment'] = reviews['Polarity'].apply(get_sentiment)\n",
        "# Filter only negative reviews\n",
        "negative_reviews = reviews[reviews['Sentiment'] == 'Negative']\n",
        "\n",
        "# Show few examples\n",
        "print(\"Sample Negative Reviews:\\n\")\n",
        "print(negative_reviews['Review Content'].head())\n",
        "\n",
        "# Count how many negative reviews\n",
        "print(\"\\nTotal Negative Reviews:\", negative_reviews.shape[0])\n",
        "\n",
        "# --- Plot: Most Common Words in Negative Reviews ---\n",
        "\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Combine all negative review texts into one string\n",
        "text = \" \".join(negative_reviews['Review Content'].tolist())\n",
        "\n",
        "# Simple cleaning: remove punctuation and numbers\n",
        "text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "\n",
        "# Split into words\n",
        "words = text.lower().split()\n",
        "\n",
        "# Optional: Remove very common English stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = [word for word in words if word not in stop_words and len(word) > 2]\n",
        "\n",
        "# Count word frequency\n",
        "word_counts = Counter(words)\n",
        "\n",
        "# Plot top 15 words\n",
        "top_words = dict(word_counts.most_common(15))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(top_words.keys(), top_words.values(), color='tomato')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Top Words in Negative Reviews')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pR4L1k0jdcIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Popularity of local businesses"
      ],
      "metadata": {
        "id": "xUNp1mP2gZPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/Ambition Box.csv')\n",
        "\n",
        "data = data.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "data['review'] = data['review'].apply(lambda x: float(re.sub(r'[^\\d\\.]', '', x)))\n",
        "\n",
        "data['company_type'] = data['company_type'].str.strip().str.capitalize()\n",
        "\n",
        "data['Company_Age'] = data['Company_Age'].apply(lambda x: int(re.search(r'\\d+', x).group()) if pd.notnull(x) else None)\n",
        "\n",
        "data['No_of_Employee'] = data['No_of_Employee'].str.strip()\n",
        "\n",
        "# Top 10 companies by rating\n",
        "top_companies = data.sort_values(by='rating', ascending=False).head(10)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(top_companies['name'], top_companies['rating'], color='cornflowerblue')\n",
        "plt.xlabel('Rating')\n",
        "plt.title('Top 10 Companies by Rating')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# Rating vs Reviews Scatter Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(data['review'], data['rating'], color='seagreen')\n",
        "plt.xlabel('Number of Reviews (in Thousands)')\n",
        "plt.ylabel('Rating')\n",
        "plt.title('Rating vs Number of Reviews')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b2ryOvANgZk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hotel Tweet Analysis"
      ],
      "metadata": {
        "id": "ZYgqvmrjgjkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset: https://www.kaggle.com/code/jonathanoheix/sentiment-analysis-with-hotel-reviews/input\n",
        "\n",
        "import pandas as pd\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/SMA/unzipped_folder/Hotel_Reviews.csv')\n",
        "\n",
        "df = df.head(100)\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_sentiment_score(text):\n",
        "    if pd.isnull(text) or text.strip() == '':\n",
        "        return 0\n",
        "    return sid.polarity_scores(text)['compound']\n",
        "\n",
        "# Apply sentiment analysis\n",
        "df['Positive_Sentiment'] = df['Positive_Review'].apply(get_sentiment_score)\n",
        "df['Negative_Sentiment'] = df['Negative_Review'].apply(get_sentiment_score)\n",
        "\n",
        "positive_text = \" \".join(df['Positive_Review'].dropna().tolist())\n",
        "\n",
        "negative_text = \" \".join(df['Negative_Review'].dropna().tolist())\n",
        "\n",
        "wordcloud_pos = WordCloud(width=800, height=400, background_color='white', colormap='Greens').generate(positive_text)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud_pos, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('WordCloud for Positive Reviews')\n",
        "plt.show()\n",
        "\n",
        "# Generate WordCloud for Negative Reviews\n",
        "wordcloud_neg = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_text)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud_neg, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('WordCloud for Negative Reviews')\n",
        "plt.show()\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot Positive Sentiment Distribution\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df['Positive_Sentiment'], bins=20, kde=True, color='green')\n",
        "plt.title('Distribution of Positive Sentiment Scores')\n",
        "plt.xlabel('Sentiment Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Plot Negative Sentiment Distribution\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df['Negative_Sentiment'], bins=20, kde=True, color='red')\n",
        "plt.title('Distribution of Negative Sentiment Scores')\n",
        "plt.xlabel('Sentiment Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aEFbkNY4gazW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis of product"
      ],
      "metadata": {
        "id": "M0SImCZylQmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset-https://www.kaggle.com/code/benroshan/sentiment-analysis-amazon-reviews/input?select=Musical_instruments_reviews.csv\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import seaborn as sns\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/Musical_instruments_reviews.csv')\n",
        "\n",
        "# Initialize VADER sentiment analyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to get sentiment score\n",
        "def get_sentiment(text):\n",
        "    if pd.isnull(text) or text.strip() == '':\n",
        "        return 0\n",
        "    return sid.polarity_scores(text)['compound']\n",
        "\n",
        "# Apply sentiment analysis on reviewText\n",
        "df['sentiment_score'] = df['reviewText'].apply(get_sentiment)\n",
        "\n",
        "# Classify sentiment\n",
        "def classify_sentiment(score):\n",
        "    if score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif score <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "df['sentiment_label'] = df['sentiment_score'].apply(classify_sentiment)\n",
        "\n",
        "# Display sample output\n",
        "print(df[['reviewerName', 'reviewText', 'sentiment_score', 'sentiment_label']].head())\n",
        "\n",
        "# --- Visualization 1: Sentiment Distribution ---\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.countplot(x='sentiment_label', data=df, palette='Set2')\n",
        "plt.title('Sentiment Distribution of Musical Instrument Reviews')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.show()\n",
        "\n",
        "# --- Visualization 2: WordCloud for Positive Reviews ---\n",
        "positive_reviews = \" \".join(df[df['sentiment_label']=='Positive']['reviewText'].dropna().tolist())\n",
        "\n",
        "wordcloud_pos = WordCloud(width=800, height=400, background_color='white', colormap='Greens').generate(positive_reviews)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud_pos, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('WordCloud for Positive Reviews')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tHI_ICtYlSFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Social Network data analysis   "
      ],
      "metadata": {
        "id": "SyVH12_0mPK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset-https://snap.stanford.edu/data/email-Eu-core.html\n",
        "import networkx as nx\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "def load_email_network(file_path):\n",
        "    G = nx.Graph()\n",
        "    with gzip.open(file_path, 'rt') as f:\n",
        "        for line in f:\n",
        "            u, v = map(int, line.strip().split())\n",
        "            G.add_edge(u, v)\n",
        "    return G\n",
        "\n",
        "# Compute centrality measures\n",
        "def compute_centrality_measures(G):\n",
        "    degree_centrality = nx.degree_centrality(G)\n",
        "    betweenness_centrality = nx.betweenness_centrality(G)\n",
        "    closeness_centrality = nx.closeness_centrality(G)\n",
        "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
        "\n",
        "    return {\n",
        "        \"degree\": degree_centrality,\n",
        "        \"betweenness\": betweenness_centrality,\n",
        "        \"closeness\": closeness_centrality,\n",
        "        \"eigenvector\": eigenvector_centrality\n",
        "    }\n",
        "\n",
        "# Perform community detection\n",
        "def detect_communities(G):\n",
        "    from networkx.algorithms.community import greedy_modularity_communities\n",
        "    communities = list(greedy_modularity_communities(G))\n",
        "    return communities\n",
        "\n",
        "# Visualize network\n",
        "def visualize_network(G, title=\"Email Network\"):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    nx.draw(G, pos, node_size=50, edge_color=\"gray\", with_labels=False)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Main Execution\n",
        "file_path = \"/content/email-Eu-core.txt.gz\"\n",
        "G = load_email_network(file_path)\n",
        "centrality_measures = compute_centrality_measures(G)\n",
        "communities = detect_communities(G)\n",
        "visualize_network(G)\n",
        "\n",
        "# Print results as per the PDF output format\n",
        "print(\"Degree Centrality:\")\n",
        "top_degree = sorted(centrality_measures[\"degree\"].items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "for node, centrality in top_degree:\n",
        "    print(f\"Node {node}: {centrality:.4f}\")\n",
        "\n",
        "print(\"\\nBetweenness Centrality:\")\n",
        "top_betweenness = sorted(centrality_measures[\"betweenness\"].items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "for node, centrality in top_betweenness:\n",
        "    print(f\"Node {node}: {centrality:.4f}\")\n",
        "\n",
        "print(\"\\nCloseness Centrality:\")\n",
        "top_closeness = sorted(centrality_measures[\"closeness\"].items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "for node, centrality in top_closeness:\n",
        "    print(f\"Node {node}: {centrality:.4f}\")\n",
        "\n",
        "print(\"\\nEigenvector Centrality:\")\n",
        "top_eigenvector = sorted(centrality_measures[\"eigenvector\"].items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "for node, centrality in top_eigenvector:\n",
        "    print(f\"Node {node}: {centrality:.4f}\")\n",
        "\n",
        "print(\"\\nDetected Communities (First 5 groups shown):\")\n",
        "for i, community in enumerate(communities[:5]):\n",
        "    print(f\"Community {i + 1}: {sorted(community)[:10]} ...\")\n"
      ],
      "metadata": {
        "id": "sIRn5zvQmPdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictive model for airline tweet"
      ],
      "metadata": {
        "id": "YBr4bYmIv5kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset-https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment/data\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/Tweets.csv')\n",
        "\n",
        "# Look at important columns\n",
        "print(df.columns)\n",
        "\n",
        "# Use only 'text' and 'airline_sentiment' columns\n",
        "df = df[['text', 'airline_sentiment']]\n",
        "\n",
        "# Remove missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Split into input and output\n",
        "X = df['text']\n",
        "y = df['airline_sentiment']\n",
        "\n",
        "# Convert text into numbers (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_vect = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Show classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Plot sentiment distribution\n",
        "df['airline_sentiment'].value_counts().plot(kind='bar', color=['red', 'blue', 'green'])\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9Yv6xIOdv8sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coaching class reviews\n"
      ],
      "metadata": {
        "id": "W82jplh3xZRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset-https://www.kaggle.com/datasets/septa97/100k-courseras-course-reviews-dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/coaching/reviews.csv')  # replace with your file name\n",
        "\n",
        "# Basic info\n",
        "print(df.head())\n",
        "df=df.head(100)\n",
        "\n",
        "# --- Sentiment Analysis ---\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_sentiment_score(text):\n",
        "    if pd.isnull(text) or text.strip() == '':\n",
        "        return 0\n",
        "    return sid.polarity_scores(text)['compound']\n",
        "\n",
        "# Add sentiment score\n",
        "df['Sentiment_Score'] = df['Review'].apply(get_sentiment_score)\n",
        "\n",
        "# Classify into Positive, Neutral, Negative based on score\n",
        "def classify(score):\n",
        "    if score > 0.2:\n",
        "        return 'Positive'\n",
        "    elif score < -0.2:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "df['Sentiment'] = df['Sentiment_Score'].apply(classify)\n",
        "\n",
        "# --- Visualization ---\n",
        "\n",
        "# 1. Sentiment distribution\n",
        "df['Sentiment'].value_counts().plot(kind='bar', color=['green', 'blue', 'red'])\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.show()\n",
        "\n",
        "# 2. WordCloud for all reviews\n",
        "text = \" \".join(review for review in df['Review'].dropna())\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('WordCloud of Course Reviews')\n",
        "plt.show()\n",
        "\n",
        "# 3. Distribution of Labels\n",
        "df['Label'].value_counts().sort_index().plot(kind='bar', color='purple')\n",
        "plt.title('Rating Label Distribution')\n",
        "plt.xlabel('Label (Rating)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K72zoHxixa9a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}